{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA6voa5EO1I-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset_new.csv\", header=None)"
      ],
      "metadata": {
        "id": "Hq_6W_kNWaen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LOQn7uBRW_XX",
        "outputId": "a556f956-9997-4f4c-85bf-4b632fefcdd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0       1       2       3       4       5       6       7       8   \\\n",
              "0      0.0065  0.0130  0.0195  0.0260  0.0325  0.0390  0.0455  0.0520  0.0585   \n",
              "1      0.0263  0.0526  0.0789  0.1052  0.1316  0.1579  0.1842  0.2105  0.2368   \n",
              "2      0.0176  0.0352  0.0528  0.0704  0.0881  0.1057  0.1233  0.1409  0.1585   \n",
              "3      0.0222  0.0444  0.0666  0.0888  0.1110  0.1332  0.1554  0.1776  0.1998   \n",
              "4      0.0189  0.0379  0.0568  0.0758  0.0947  0.1137  0.1326  0.1516  0.1705   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "19995  0.0639  0.1278  0.1918  0.2557  0.3196  0.3835  0.4474  0.5114  0.5753   \n",
              "19996  0.0830  0.1659  0.2489  0.3318  0.4148  0.4977  0.5807  0.6637  0.7466   \n",
              "19997  0.0854  0.1709  0.2563  0.3417  0.4272  0.5126  0.5980  0.6835  0.7689   \n",
              "19998  0.0648  0.1296  0.1945  0.2593  0.3241  0.3889  0.4537  0.5186  0.5834   \n",
              "19999  0.3579  0.7158  1.0737  1.4316  1.7895  2.1473  2.5052  2.8631  3.2210   \n",
              "\n",
              "           9   ...      45      46      47      48      49      50      51  \\\n",
              "0      0.0650  ...  0.0316  0.0368  0.0312  0.0000  0.0316  0.0364  0.0304   \n",
              "1      0.2631  ...  0.0316  0.0368  0.0312  0.0000  0.0316  0.0364  0.0304   \n",
              "2      0.1761  ...  0.0316  0.0368  0.0312  0.0312  0.0316  0.0299  0.0304   \n",
              "3      0.2220  ...  0.0316  0.0307  0.0312  0.0000  0.0360  0.0364  0.0304   \n",
              "4      0.1895  ...  0.0316  0.0368  0.0312  0.0000  0.0316  0.0364  0.0304   \n",
              "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "19995  0.6392  ...  0.0000  0.0000  0.0000  0.0028  0.0284  0.0076  0.0048   \n",
              "19996  0.8296  ...  0.0000  0.0000  0.0000  0.0028  0.0284  0.0076  0.0048   \n",
              "19997  0.8543  ...  0.0000  0.0000  0.0000  0.0028  0.0284  0.0076  0.0048   \n",
              "19998  0.6482  ...  0.0000  0.0000  0.0000  0.0277  0.0284  0.0076  0.0048   \n",
              "19999  3.5789  ...  0.0000  0.0017  0.0027  0.0033  0.0000  0.0001  0.0034   \n",
              "\n",
              "           52      53  54  \n",
              "0      0.0604  0.9960   1  \n",
              "1      0.0604  0.9960   1  \n",
              "2      0.0604  0.9957   1  \n",
              "3      0.0604  0.9900   1  \n",
              "4      0.0604  0.9862   1  \n",
              "...       ...     ...  ..  \n",
              "19995  0.1793  0.9856   0  \n",
              "19996  0.1793  0.9849   0  \n",
              "19997  0.1793  0.9825   0  \n",
              "19998  0.1793  0.9782   0  \n",
              "19999  0.3056  0.9166   0  \n",
              "\n",
              "[20000 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc447241-896e-4a32-ab63-03c90077d575\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0325</td>\n",
              "      <td>0.0390</td>\n",
              "      <td>0.0455</td>\n",
              "      <td>0.0520</td>\n",
              "      <td>0.0585</td>\n",
              "      <td>0.0650</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>0.9960</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0263</td>\n",
              "      <td>0.0526</td>\n",
              "      <td>0.0789</td>\n",
              "      <td>0.1052</td>\n",
              "      <td>0.1316</td>\n",
              "      <td>0.1579</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.2368</td>\n",
              "      <td>0.2631</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>0.9960</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0704</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1233</td>\n",
              "      <td>0.1409</td>\n",
              "      <td>0.1585</td>\n",
              "      <td>0.1761</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0299</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>0.9957</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0888</td>\n",
              "      <td>0.1110</td>\n",
              "      <td>0.1332</td>\n",
              "      <td>0.1554</td>\n",
              "      <td>0.1776</td>\n",
              "      <td>0.1998</td>\n",
              "      <td>0.2220</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0307</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>0.9900</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0189</td>\n",
              "      <td>0.0379</td>\n",
              "      <td>0.0568</td>\n",
              "      <td>0.0758</td>\n",
              "      <td>0.0947</td>\n",
              "      <td>0.1137</td>\n",
              "      <td>0.1326</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.1705</td>\n",
              "      <td>0.1895</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0364</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.0604</td>\n",
              "      <td>0.9862</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>0.0639</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>0.1918</td>\n",
              "      <td>0.2557</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.4474</td>\n",
              "      <td>0.5114</td>\n",
              "      <td>0.5753</td>\n",
              "      <td>0.6392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.9856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>0.0830</td>\n",
              "      <td>0.1659</td>\n",
              "      <td>0.2489</td>\n",
              "      <td>0.3318</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4977</td>\n",
              "      <td>0.5807</td>\n",
              "      <td>0.6637</td>\n",
              "      <td>0.7466</td>\n",
              "      <td>0.8296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.9849</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>0.0854</td>\n",
              "      <td>0.1709</td>\n",
              "      <td>0.2563</td>\n",
              "      <td>0.3417</td>\n",
              "      <td>0.4272</td>\n",
              "      <td>0.5126</td>\n",
              "      <td>0.5980</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.7689</td>\n",
              "      <td>0.8543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.9825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>0.0648</td>\n",
              "      <td>0.1296</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2593</td>\n",
              "      <td>0.3241</td>\n",
              "      <td>0.3889</td>\n",
              "      <td>0.4537</td>\n",
              "      <td>0.5186</td>\n",
              "      <td>0.5834</td>\n",
              "      <td>0.6482</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.9782</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>0.3579</td>\n",
              "      <td>0.7158</td>\n",
              "      <td>1.0737</td>\n",
              "      <td>1.4316</td>\n",
              "      <td>1.7895</td>\n",
              "      <td>2.1473</td>\n",
              "      <td>2.5052</td>\n",
              "      <td>2.8631</td>\n",
              "      <td>3.2210</td>\n",
              "      <td>3.5789</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.3056</td>\n",
              "      <td>0.9166</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc447241-896e-4a32-ab63-03c90077d575')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc447241-896e-4a32-ab63-03c90077d575 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc447241-896e-4a32-ab63-03c90077d575');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMIe7jS5XYGD",
        "outputId": "eef07888-324c-4452-fcf2-8af4ca420e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 55)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Reshape,Dense,Dropout,Activation,Flatten, Conv2D, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "NzYporTDXZEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data(data):\n",
        "    data = np.transpose(data)\n",
        "    scalar = MinMaxScaler((0,1))\n",
        "    scalar.fit(data)\n",
        "    data = scalar.transform(data)\n",
        "    output = np.transpose(data)\n",
        "    return output"
      ],
      "metadata": {
        "id": "R9-tcSfeXZOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Low_traffic', 'High_traffic']\n",
        "num_classes = len(classes)\n",
        "in_dim = [2, 13]\n",
        "X = df.iloc[:,0:26].to_numpy()\n",
        "Y = df.iloc[:,26:52].to_numpy()\n",
        "IPI = df.iloc[:,52].to_numpy()\n",
        "Label = df.iloc[:,54].to_numpy()\n",
        "Label_cat = tf.keras.utils.to_categorical(Label,num_classes)\n",
        "IPI_max = np.amax(IPI)\n",
        "IPI = np.divide(IPI, IPI_max)"
      ],
      "metadata": {
        "id": "8Zwjm56HXZQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(np.array(X).flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "w_ktgmgKXZUD",
        "outputId": "ec016934-d9af-4e1a-f89f-ed77d8fa10b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.86889e+05, 2.37100e+04, 5.19300e+03, 2.31100e+03, 1.10400e+03,\n",
              "        4.63000e+02, 8.00000e+01, 7.00000e+01, 8.70000e+01, 9.30000e+01]),\n",
              " array([2.300000e-03, 4.910370e+00, 9.818440e+00, 1.472651e+01,\n",
              "        1.963458e+01, 2.454265e+01, 2.945072e+01, 3.435879e+01,\n",
              "        3.926686e+01, 4.417493e+01, 4.908300e+01]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=int(time.time()))\n",
        "n_examples = X.shape[0]\n",
        "n_train = n_examples * 0.7\n",
        "train_idx = np.random.choice(range(0,n_examples), size=int(n_train), replace=False)\n",
        "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
        "X_train = X[train_idx]\n",
        "X_test = X[test_idx]\n",
        "Y_train = Y[train_idx]\n",
        "Y_test = Y[test_idx]\n",
        "IPI_train = IPI[train_idx]\n",
        "IPI_test = IPI[test_idx]\n",
        "Label_train = Label_cat[train_idx]\n",
        "Label_test = Label_cat[test_idx]"
      ],
      "metadata": {
        "id": "vEJBePcwXuaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(X_shape, Y_shape, IPI_shape, classes, verbose):\n",
        "\n",
        "    dr = 0.40\n",
        "\n",
        "    model_X = tf.keras.models.Sequential()\n",
        "    model_X.add(layers.Reshape((X_shape, 1), input_shape=(X_shape, ) ))\n",
        "    model_X.add(layers.Conv1D(32, 3, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_X.add(layers.BatchNormalization())\n",
        "    model_X.add(layers.Conv1D(16, 2, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_X.add(layers.Flatten())\n",
        "    model_X.add(layers.Dense(256, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_X.add(layers.Dropout(dr))\n",
        "    model_X.add(layers.Dense(128, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_X.add(layers.Dropout(dr))\n",
        "\n",
        "    model_Y = tf.keras.models.Sequential()\n",
        "    model_Y.add(layers.Reshape((Y_shape, 1), input_shape=(Y_shape, ) ))\n",
        "    model_Y.add(layers.Conv1D(32, 3, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01) ))\n",
        "    model_Y.add(layers.BatchNormalization())\n",
        "    model_Y.add(layers.Conv1D(16, 2, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_Y.add(layers.Flatten())\n",
        "    model_Y.add(layers.Dropout(dr))\n",
        "    model_Y.add(layers.Dense(256, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01) ))\n",
        "    model_Y.add(layers.Dropout(dr))\n",
        "    model_Y.add(layers.Dense(128, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_Y.add(layers.Dropout(dr))\n",
        "\n",
        "    model_IPI = tf.keras.models.Sequential()\n",
        "    model_IPI.add(layers.Dense(IPI_shape, activation=tf.nn.relu, input_shape=(IPI_shape, )))\n",
        "\n",
        "    model_IPI.add(layers.Dense(64, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_IPI.add(layers.Dropout(dr))\n",
        "    model_IPI.add(layers.Dense(32, activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01)))\n",
        "    model_IPI.add(layers.Dropout(dr))\n",
        "\n",
        "\n",
        "    merged = tf.keras.layers.Concatenate(axis=1)([model_X.output, model_Y.output, model_IPI.output])\n",
        "    merged = layers.Dense(256,activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01))(merged)\n",
        "    merged = layers.Dropout(dr)(merged)\n",
        "    merged = layers.Dense(128,activation=tf.nn.relu, kernel_regularizer=regularizers.l2(0.01))(merged)\n",
        "    merged = layers.Dropout(dr)(merged)\n",
        "    merged = layers.Dense(len(classes), activation=tf.nn.softmax, name='class_output')(merged)\n",
        "\n",
        "    model = tf.keras.models.Model([model_X.input,model_Y.input, model_IPI.input], merged)\n",
        "\n",
        "\n",
        "    if(verbose):\n",
        "        from tensorflow.keras.utils import plot_model\n",
        "        from IPython.display import Image\n",
        "        plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "    print(\"--Model created\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "f09RUB8MXuio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(X.shape[1], Y.shape[1], 1, classes, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPQlvjW7XumF",
        "outputId": "6e250020-1d72-4aa6-b828-1574693a0dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Model created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H20YOq7sYYR8",
        "outputId": "4eb67e35-4299-4b6d-d7e0-2a88f091e1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " reshape_1_input (InputLayer)   [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_input (InputLayer)     [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 26, 1)        0           ['reshape_1_input[0][0]']        \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 26, 1)        0           ['reshape_input[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 24, 32)       128         ['reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 24, 32)       128         ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 24, 32)      128         ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 24, 32)      128         ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 23, 16)       1040        ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 23, 16)       1040        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 368)          0           ['conv1d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4_input (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 368)          0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 368)          0           ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            2           ['dense_4_input[0][0]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          94464       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          94464       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 64)           128         ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          32896       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 32)           2080        ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 288)          0           ['dropout_1[0][0]',              \n",
            "                                                                  'dropout_4[0][0]',              \n",
            "                                                                  'dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 256)          73984       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 256)          0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          32896       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 128)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " class_output (Dense)           (None, 2)            258         ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 366,660\n",
            "Trainable params: 366,532\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss= 'categorical_crossentropy', metrics=['accuracy']  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB0Qa8G5YYVO",
        "outputId": "98df2ece-d1f7-47b8-ec90-b3ad83eb7951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savedir = 'model_LTE_WiFi_coexistance_histogram+IPI.h5'\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'loss', min_delta = 0, patience = 20, verbose = 0, mode = 'auto')\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(savedir, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
        "reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, min_delta=0.00001, cooldown=0, min_lr=0.0001)\n",
        "nb_epoch = 5000\n",
        "batch_size = 16\n",
        "history = model.fit(x = [X_train, Y_train, np.transpose(IPI_train)], y = Label_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=nb_epoch,\n",
        "                    validation_data = ([X_test, Y_test, np.transpose(IPI_test)], Label_test),\n",
        "                    shuffle=True,\n",
        "                    verbose=2,\n",
        "                    callbacks = [early_stop, checkpoint, reduce_lr_callback] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-N97sqoYk6r",
        "outputId": "9be4ff90-1c17-4fc2-cfb5-8311cfdf75aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000\n",
            "\n",
            "Epoch 1: loss improved from inf to 1.34193, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 14s - loss: 1.3419 - accuracy: 0.9391 - val_loss: 0.2511 - val_accuracy: 0.9578 - lr: 0.0010 - 14s/epoch - 16ms/step\n",
            "Epoch 2/5000\n",
            "\n",
            "Epoch 2: loss improved from 1.34193 to 0.25240, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 6s - loss: 0.2524 - accuracy: 0.9527 - val_loss: 0.2161 - val_accuracy: 0.9592 - lr: 0.0010 - 6s/epoch - 7ms/step\n",
            "Epoch 3/5000\n",
            "\n",
            "Epoch 3: loss improved from 0.25240 to 0.23612, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.2361 - accuracy: 0.9512 - val_loss: 0.2171 - val_accuracy: 0.9528 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 4/5000\n",
            "\n",
            "Epoch 4: loss improved from 0.23612 to 0.22473, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.2247 - accuracy: 0.9545 - val_loss: 0.2024 - val_accuracy: 0.9570 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
            "Epoch 5/5000\n",
            "\n",
            "Epoch 5: loss improved from 0.22473 to 0.21886, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.2189 - accuracy: 0.9543 - val_loss: 0.1889 - val_accuracy: 0.9618 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 6/5000\n",
            "\n",
            "Epoch 6: loss improved from 0.21886 to 0.21744, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.2174 - accuracy: 0.9542 - val_loss: 0.1883 - val_accuracy: 0.9603 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 7/5000\n",
            "\n",
            "Epoch 7: loss improved from 0.21744 to 0.21281, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.2128 - accuracy: 0.9543 - val_loss: 0.2021 - val_accuracy: 0.9573 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 8/5000\n",
            "\n",
            "Epoch 8: loss improved from 0.21281 to 0.20184, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.2018 - accuracy: 0.9576 - val_loss: 0.2051 - val_accuracy: 0.9583 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 9/5000\n",
            "\n",
            "Epoch 9: loss improved from 0.20184 to 0.19974, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1997 - accuracy: 0.9604 - val_loss: 0.2354 - val_accuracy: 0.9497 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 10/5000\n",
            "\n",
            "Epoch 10: loss improved from 0.19974 to 0.19878, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1988 - accuracy: 0.9581 - val_loss: 0.1775 - val_accuracy: 0.9640 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 11/5000\n",
            "\n",
            "Epoch 11: loss improved from 0.19878 to 0.19253, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1925 - accuracy: 0.9610 - val_loss: 0.1878 - val_accuracy: 0.9583 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 12/5000\n",
            "\n",
            "Epoch 12: loss did not improve from 0.19253\n",
            "875/875 - 7s - loss: 0.1979 - accuracy: 0.9583 - val_loss: 0.1861 - val_accuracy: 0.9570 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
            "Epoch 13/5000\n",
            "\n",
            "Epoch 13: loss improved from 0.19253 to 0.19189, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1919 - accuracy: 0.9602 - val_loss: 0.1981 - val_accuracy: 0.9572 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 14/5000\n",
            "\n",
            "Epoch 14: loss did not improve from 0.19189\n",
            "875/875 - 7s - loss: 0.1943 - accuracy: 0.9589 - val_loss: 0.1863 - val_accuracy: 0.9623 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 15/5000\n",
            "\n",
            "Epoch 15: loss improved from 0.19189 to 0.18786, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1879 - accuracy: 0.9614 - val_loss: 0.1760 - val_accuracy: 0.9632 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 16/5000\n",
            "\n",
            "Epoch 16: loss did not improve from 0.18786\n",
            "875/875 - 7s - loss: 0.1883 - accuracy: 0.9611 - val_loss: 0.1636 - val_accuracy: 0.9688 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 17/5000\n",
            "\n",
            "Epoch 17: loss improved from 0.18786 to 0.18423, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1842 - accuracy: 0.9620 - val_loss: 0.1669 - val_accuracy: 0.9667 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 18/5000\n",
            "\n",
            "Epoch 18: loss did not improve from 0.18423\n",
            "875/875 - 7s - loss: 0.1878 - accuracy: 0.9605 - val_loss: 0.1607 - val_accuracy: 0.9720 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 19/5000\n",
            "\n",
            "Epoch 19: loss improved from 0.18423 to 0.18012, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1801 - accuracy: 0.9645 - val_loss: 0.2062 - val_accuracy: 0.9582 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 20/5000\n",
            "\n",
            "Epoch 20: loss did not improve from 0.18012\n",
            "875/875 - 7s - loss: 0.1853 - accuracy: 0.9631 - val_loss: 0.1654 - val_accuracy: 0.9680 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 21/5000\n",
            "\n",
            "Epoch 21: loss did not improve from 0.18012\n",
            "875/875 - 7s - loss: 0.1816 - accuracy: 0.9639 - val_loss: 0.1730 - val_accuracy: 0.9637 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 22/5000\n",
            "\n",
            "Epoch 22: loss improved from 0.18012 to 0.17997, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1800 - accuracy: 0.9629 - val_loss: 0.1533 - val_accuracy: 0.9693 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 23/5000\n",
            "\n",
            "Epoch 23: loss did not improve from 0.17997\n",
            "875/875 - 7s - loss: 0.1817 - accuracy: 0.9638 - val_loss: 0.1505 - val_accuracy: 0.9683 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 24/5000\n",
            "\n",
            "Epoch 24: loss did not improve from 0.17997\n",
            "875/875 - 8s - loss: 0.1815 - accuracy: 0.9621 - val_loss: 0.1793 - val_accuracy: 0.9577 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 25/5000\n",
            "\n",
            "Epoch 25: loss did not improve from 0.17997\n",
            "875/875 - 8s - loss: 0.1839 - accuracy: 0.9633 - val_loss: 0.1609 - val_accuracy: 0.9697 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 26/5000\n",
            "\n",
            "Epoch 26: loss improved from 0.17997 to 0.17621, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 6s - loss: 0.1762 - accuracy: 0.9641 - val_loss: 0.1649 - val_accuracy: 0.9663 - lr: 0.0010 - 6s/epoch - 7ms/step\n",
            "Epoch 27/5000\n",
            "\n",
            "Epoch 27: loss improved from 0.17621 to 0.17551, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1755 - accuracy: 0.9646 - val_loss: 0.1708 - val_accuracy: 0.9645 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 28/5000\n",
            "\n",
            "Epoch 28: loss did not improve from 0.17551\n",
            "875/875 - 7s - loss: 0.1790 - accuracy: 0.9649 - val_loss: 0.1475 - val_accuracy: 0.9737 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 29/5000\n",
            "\n",
            "Epoch 29: loss did not improve from 0.17551\n",
            "875/875 - 8s - loss: 0.1785 - accuracy: 0.9631 - val_loss: 0.1590 - val_accuracy: 0.9702 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 30/5000\n",
            "\n",
            "Epoch 30: loss did not improve from 0.17551\n",
            "875/875 - 8s - loss: 0.1773 - accuracy: 0.9642 - val_loss: 0.2337 - val_accuracy: 0.9470 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 31/5000\n",
            "\n",
            "Epoch 31: loss improved from 0.17551 to 0.17487, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1749 - accuracy: 0.9657 - val_loss: 0.2139 - val_accuracy: 0.9550 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 32/5000\n",
            "\n",
            "Epoch 32: loss did not improve from 0.17487\n",
            "875/875 - 7s - loss: 0.1749 - accuracy: 0.9656 - val_loss: 0.1501 - val_accuracy: 0.9715 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 33/5000\n",
            "\n",
            "Epoch 33: loss improved from 0.17487 to 0.17276, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1728 - accuracy: 0.9653 - val_loss: 0.1629 - val_accuracy: 0.9713 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 34/5000\n",
            "\n",
            "Epoch 34: loss did not improve from 0.17276\n",
            "875/875 - 7s - loss: 0.1795 - accuracy: 0.9634 - val_loss: 0.1623 - val_accuracy: 0.9677 - lr: 0.0010 - 7s/epoch - 9ms/step\n",
            "Epoch 35/5000\n",
            "\n",
            "Epoch 35: loss improved from 0.17276 to 0.17016, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1702 - accuracy: 0.9660 - val_loss: 0.1498 - val_accuracy: 0.9740 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 36/5000\n",
            "\n",
            "Epoch 36: loss did not improve from 0.17016\n",
            "875/875 - 7s - loss: 0.1707 - accuracy: 0.9653 - val_loss: 0.1576 - val_accuracy: 0.9692 - lr: 0.0010 - 7s/epoch - 9ms/step\n",
            "Epoch 37/5000\n",
            "\n",
            "Epoch 37: loss did not improve from 0.17016\n",
            "875/875 - 8s - loss: 0.1741 - accuracy: 0.9644 - val_loss: 0.1431 - val_accuracy: 0.9765 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 38/5000\n",
            "\n",
            "Epoch 38: loss did not improve from 0.17016\n",
            "875/875 - 7s - loss: 0.1713 - accuracy: 0.9650 - val_loss: 0.1612 - val_accuracy: 0.9683 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 39/5000\n",
            "\n",
            "Epoch 39: loss did not improve from 0.17016\n",
            "875/875 - 7s - loss: 0.1723 - accuracy: 0.9661 - val_loss: 0.1385 - val_accuracy: 0.9768 - lr: 0.0010 - 7s/epoch - 9ms/step\n",
            "Epoch 40/5000\n",
            "\n",
            "Epoch 40: loss improved from 0.17016 to 0.16884, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1688 - accuracy: 0.9655 - val_loss: 0.1704 - val_accuracy: 0.9675 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 41/5000\n",
            "\n",
            "Epoch 41: loss did not improve from 0.16884\n",
            "875/875 - 8s - loss: 0.1750 - accuracy: 0.9654 - val_loss: 0.1658 - val_accuracy: 0.9720 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 42/5000\n",
            "\n",
            "Epoch 42: loss improved from 0.16884 to 0.16704, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1670 - accuracy: 0.9679 - val_loss: 0.1834 - val_accuracy: 0.9573 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 43/5000\n",
            "\n",
            "Epoch 43: loss did not improve from 0.16704\n",
            "875/875 - 6s - loss: 0.1722 - accuracy: 0.9659 - val_loss: 0.1480 - val_accuracy: 0.9773 - lr: 0.0010 - 6s/epoch - 7ms/step\n",
            "Epoch 44/5000\n",
            "\n",
            "Epoch 44: loss did not improve from 0.16704\n",
            "875/875 - 7s - loss: 0.1712 - accuracy: 0.9676 - val_loss: 0.1458 - val_accuracy: 0.9748 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 45/5000\n",
            "\n",
            "Epoch 45: loss did not improve from 0.16704\n",
            "875/875 - 6s - loss: 0.1683 - accuracy: 0.9672 - val_loss: 0.1388 - val_accuracy: 0.9762 - lr: 0.0010 - 6s/epoch - 7ms/step\n",
            "Epoch 46/5000\n",
            "\n",
            "Epoch 46: loss did not improve from 0.16704\n",
            "875/875 - 7s - loss: 0.1697 - accuracy: 0.9656 - val_loss: 0.1466 - val_accuracy: 0.9732 - lr: 0.0010 - 7s/epoch - 9ms/step\n",
            "Epoch 47/5000\n",
            "\n",
            "Epoch 47: loss did not improve from 0.16704\n",
            "875/875 - 6s - loss: 0.1693 - accuracy: 0.9678 - val_loss: 0.1405 - val_accuracy: 0.9753 - lr: 0.0010 - 6s/epoch - 7ms/step\n",
            "Epoch 48/5000\n",
            "\n",
            "Epoch 48: loss did not improve from 0.16704\n",
            "875/875 - 8s - loss: 0.1705 - accuracy: 0.9659 - val_loss: 0.1452 - val_accuracy: 0.9742 - lr: 0.0010 - 8s/epoch - 9ms/step\n",
            "Epoch 49/5000\n",
            "\n",
            "Epoch 49: loss improved from 0.16704 to 0.16624, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "875/875 - 7s - loss: 0.1662 - accuracy: 0.9656 - val_loss: 0.1414 - val_accuracy: 0.9755 - lr: 0.0010 - 7s/epoch - 8ms/step\n",
            "Epoch 50/5000\n",
            "\n",
            "Epoch 50: loss improved from 0.16624 to 0.15095, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1509 - accuracy: 0.9722 - val_loss: 0.1263 - val_accuracy: 0.9782 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 51/5000\n",
            "\n",
            "Epoch 51: loss improved from 0.15095 to 0.14374, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1437 - accuracy: 0.9726 - val_loss: 0.1236 - val_accuracy: 0.9762 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 52/5000\n",
            "\n",
            "Epoch 52: loss improved from 0.14374 to 0.13670, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1367 - accuracy: 0.9744 - val_loss: 0.1203 - val_accuracy: 0.9770 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 53/5000\n",
            "\n",
            "Epoch 53: loss did not improve from 0.13670\n",
            "875/875 - 7s - loss: 0.1405 - accuracy: 0.9711 - val_loss: 0.1219 - val_accuracy: 0.9750 - lr: 1.0000e-04 - 7s/epoch - 9ms/step\n",
            "Epoch 54/5000\n",
            "\n",
            "Epoch 54: loss did not improve from 0.13670\n",
            "875/875 - 6s - loss: 0.1395 - accuracy: 0.9716 - val_loss: 0.1170 - val_accuracy: 0.9760 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 55/5000\n",
            "\n",
            "Epoch 55: loss did not improve from 0.13670\n",
            "875/875 - 7s - loss: 0.1375 - accuracy: 0.9724 - val_loss: 0.1172 - val_accuracy: 0.9772 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 56/5000\n",
            "\n",
            "Epoch 56: loss improved from 0.13670 to 0.13629, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1363 - accuracy: 0.9722 - val_loss: 0.1247 - val_accuracy: 0.9740 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 57/5000\n",
            "\n",
            "Epoch 57: loss did not improve from 0.13629\n",
            "875/875 - 7s - loss: 0.1365 - accuracy: 0.9719 - val_loss: 0.1260 - val_accuracy: 0.9737 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 58/5000\n",
            "\n",
            "Epoch 58: loss improved from 0.13629 to 0.13482, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1348 - accuracy: 0.9733 - val_loss: 0.1151 - val_accuracy: 0.9770 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 59/5000\n",
            "\n",
            "Epoch 59: loss did not improve from 0.13482\n",
            "875/875 - 6s - loss: 0.1370 - accuracy: 0.9709 - val_loss: 0.1132 - val_accuracy: 0.9788 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 60/5000\n",
            "\n",
            "Epoch 60: loss improved from 0.13482 to 0.13123, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1312 - accuracy: 0.9746 - val_loss: 0.1134 - val_accuracy: 0.9767 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 61/5000\n",
            "\n",
            "Epoch 61: loss did not improve from 0.13123\n",
            "875/875 - 7s - loss: 0.1346 - accuracy: 0.9723 - val_loss: 0.1187 - val_accuracy: 0.9750 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 62/5000\n",
            "\n",
            "Epoch 62: loss did not improve from 0.13123\n",
            "875/875 - 7s - loss: 0.1330 - accuracy: 0.9722 - val_loss: 0.1134 - val_accuracy: 0.9758 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 63/5000\n",
            "\n",
            "Epoch 63: loss improved from 0.13123 to 0.13053, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1305 - accuracy: 0.9735 - val_loss: 0.1122 - val_accuracy: 0.9772 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 64/5000\n",
            "\n",
            "Epoch 64: loss did not improve from 0.13053\n",
            "875/875 - 8s - loss: 0.1340 - accuracy: 0.9716 - val_loss: 0.1114 - val_accuracy: 0.9792 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 65/5000\n",
            "\n",
            "Epoch 65: loss did not improve from 0.13053\n",
            "875/875 - 7s - loss: 0.1310 - accuracy: 0.9736 - val_loss: 0.1131 - val_accuracy: 0.9767 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 66/5000\n",
            "\n",
            "Epoch 66: loss did not improve from 0.13053\n",
            "875/875 - 6s - loss: 0.1329 - accuracy: 0.9726 - val_loss: 0.1148 - val_accuracy: 0.9760 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 67/5000\n",
            "\n",
            "Epoch 67: loss improved from 0.13053 to 0.13028, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1303 - accuracy: 0.9734 - val_loss: 0.1135 - val_accuracy: 0.9762 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 68/5000\n",
            "\n",
            "Epoch 68: loss improved from 0.13028 to 0.12816, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 6s - loss: 0.1282 - accuracy: 0.9741 - val_loss: 0.1121 - val_accuracy: 0.9800 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 69/5000\n",
            "\n",
            "Epoch 69: loss did not improve from 0.12816\n",
            "875/875 - 8s - loss: 0.1302 - accuracy: 0.9733 - val_loss: 0.1122 - val_accuracy: 0.9758 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 70/5000\n",
            "\n",
            "Epoch 70: loss did not improve from 0.12816\n",
            "875/875 - 6s - loss: 0.1311 - accuracy: 0.9725 - val_loss: 0.1104 - val_accuracy: 0.9793 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 71/5000\n",
            "\n",
            "Epoch 71: loss did not improve from 0.12816\n",
            "875/875 - 8s - loss: 0.1318 - accuracy: 0.9736 - val_loss: 0.1104 - val_accuracy: 0.9770 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 72/5000\n",
            "\n",
            "Epoch 72: loss did not improve from 0.12816\n",
            "875/875 - 7s - loss: 0.1321 - accuracy: 0.9721 - val_loss: 0.1114 - val_accuracy: 0.9767 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 73/5000\n",
            "\n",
            "Epoch 73: loss did not improve from 0.12816\n",
            "875/875 - 7s - loss: 0.1327 - accuracy: 0.9719 - val_loss: 0.1099 - val_accuracy: 0.9783 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 74/5000\n",
            "\n",
            "Epoch 74: loss improved from 0.12816 to 0.12761, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 8s - loss: 0.1276 - accuracy: 0.9736 - val_loss: 0.1102 - val_accuracy: 0.9768 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 75/5000\n",
            "\n",
            "Epoch 75: loss did not improve from 0.12761\n",
            "875/875 - 6s - loss: 0.1324 - accuracy: 0.9715 - val_loss: 0.1106 - val_accuracy: 0.9762 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 76/5000\n",
            "\n",
            "Epoch 76: loss did not improve from 0.12761\n",
            "875/875 - 7s - loss: 0.1305 - accuracy: 0.9723 - val_loss: 0.1056 - val_accuracy: 0.9773 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 77/5000\n",
            "\n",
            "Epoch 77: loss did not improve from 0.12761\n",
            "875/875 - 7s - loss: 0.1313 - accuracy: 0.9721 - val_loss: 0.1160 - val_accuracy: 0.9740 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 78/5000\n",
            "\n",
            "Epoch 78: loss improved from 0.12761 to 0.12560, saving model to model_LTE_WiFi_coexistance_histogram+IPI.h5\n",
            "875/875 - 7s - loss: 0.1256 - accuracy: 0.9735 - val_loss: 0.1120 - val_accuracy: 0.9755 - lr: 1.0000e-04 - 7s/epoch - 9ms/step\n",
            "Epoch 79/5000\n",
            "\n",
            "Epoch 79: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1304 - accuracy: 0.9726 - val_loss: 0.1078 - val_accuracy: 0.9748 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 80/5000\n",
            "\n",
            "Epoch 80: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1303 - accuracy: 0.9722 - val_loss: 0.1078 - val_accuracy: 0.9753 - lr: 1.0000e-04 - 7s/epoch - 9ms/step\n",
            "Epoch 81/5000\n",
            "\n",
            "Epoch 81: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1282 - accuracy: 0.9725 - val_loss: 0.1118 - val_accuracy: 0.9762 - lr: 1.0000e-04 - 7s/epoch - 9ms/step\n",
            "Epoch 82/5000\n",
            "\n",
            "Epoch 82: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1304 - accuracy: 0.9719 - val_loss: 0.1086 - val_accuracy: 0.9760 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 83/5000\n",
            "\n",
            "Epoch 83: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1293 - accuracy: 0.9729 - val_loss: 0.1166 - val_accuracy: 0.9752 - lr: 1.0000e-04 - 7s/epoch - 9ms/step\n",
            "Epoch 84/5000\n",
            "\n",
            "Epoch 84: loss did not improve from 0.12560\n",
            "875/875 - 6s - loss: 0.1282 - accuracy: 0.9724 - val_loss: 0.1077 - val_accuracy: 0.9762 - lr: 1.0000e-04 - 6s/epoch - 7ms/step\n",
            "Epoch 85/5000\n",
            "\n",
            "Epoch 85: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1311 - accuracy: 0.9714 - val_loss: 0.1054 - val_accuracy: 0.9760 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 86/5000\n",
            "\n",
            "Epoch 86: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1272 - accuracy: 0.9719 - val_loss: 0.1048 - val_accuracy: 0.9790 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 87/5000\n",
            "\n",
            "Epoch 87: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1277 - accuracy: 0.9720 - val_loss: 0.1189 - val_accuracy: 0.9715 - lr: 1.0000e-04 - 7s/epoch - 7ms/step\n",
            "Epoch 88/5000\n",
            "\n",
            "Epoch 88: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1280 - accuracy: 0.9716 - val_loss: 0.1130 - val_accuracy: 0.9743 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 89/5000\n",
            "\n",
            "Epoch 89: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1297 - accuracy: 0.9719 - val_loss: 0.1039 - val_accuracy: 0.9750 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 90/5000\n",
            "\n",
            "Epoch 90: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1275 - accuracy: 0.9724 - val_loss: 0.1034 - val_accuracy: 0.9763 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 91/5000\n",
            "\n",
            "Epoch 91: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1279 - accuracy: 0.9728 - val_loss: 0.1089 - val_accuracy: 0.9753 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 92/5000\n",
            "\n",
            "Epoch 92: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1278 - accuracy: 0.9715 - val_loss: 0.1047 - val_accuracy: 0.9758 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 93/5000\n",
            "\n",
            "Epoch 93: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1284 - accuracy: 0.9723 - val_loss: 0.1027 - val_accuracy: 0.9768 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 94/5000\n",
            "\n",
            "Epoch 94: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1278 - accuracy: 0.9725 - val_loss: 0.1046 - val_accuracy: 0.9755 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 95/5000\n",
            "\n",
            "Epoch 95: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1298 - accuracy: 0.9710 - val_loss: 0.1051 - val_accuracy: 0.9750 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 96/5000\n",
            "\n",
            "Epoch 96: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1261 - accuracy: 0.9727 - val_loss: 0.1052 - val_accuracy: 0.9748 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n",
            "Epoch 97/5000\n",
            "\n",
            "Epoch 97: loss did not improve from 0.12560\n",
            "875/875 - 8s - loss: 0.1269 - accuracy: 0.9729 - val_loss: 0.1045 - val_accuracy: 0.9748 - lr: 1.0000e-04 - 8s/epoch - 9ms/step\n",
            "Epoch 98/5000\n",
            "\n",
            "Epoch 98: loss did not improve from 0.12560\n",
            "875/875 - 7s - loss: 0.1274 - accuracy: 0.9709 - val_loss: 0.1027 - val_accuracy: 0.9758 - lr: 1.0000e-04 - 7s/epoch - 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "kFevPUuhgu8T",
        "outputId": "7e9799a3-a795-4b84-c3d8-ae411d1204ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YReX5eFygvfJ",
        "outputId": "5a5f402b-c562-4ddc-8587-6966a245875a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vqsq8jwOg8Cg",
        "outputId": "916c9b74-e2e8-4553-c676-973b1761ad69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "tEmFvVT0hBZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [X_test, Y_test, np.transpose(IPI_test)]\n",
        "\n",
        "test_Y_hat = model.predict(X, batch_size=batch_size)\n",
        "conf = np.zeros([len(classes),len(classes)])\n",
        "confnorm1 = np.zeros([len(classes),len(classes)])\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    j = list(Label_test[i,:]).index(1)\n",
        "    k = int(np.argmax(test_Y_hat[i,:]))\n",
        "    conf[j,k] = conf[j,k] + 1\n",
        "for i in range(0,len(classes)):\n",
        "    confnorm1[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "plot_confusion_matrix(confnorm1, labels=classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "daf9oaZuhG_d",
        "outputId": "3de73054-d3a1-4c3f-b591-9f37fcdfeab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confnorm1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN4JOLZdhHC7",
        "outputId": "5fd56703-5e54-46d5-9e69-10b755fd0f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.98736702 0.01263298]\n",
            " [0.03576203 0.96423797]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict([X_test, Y_test, np.transpose(IPI_test)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npTTUDZQjCQT",
        "outputId": "60a8c82a-f8c0-4912-8254-35f23e00f083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188/188 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred, axis=-1)"
      ],
      "metadata": {
        "id": "Y3y71su3jCSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Label_test = np.argmax(Label_test, axis=-1)"
      ],
      "metadata": {
        "id": "_h981exgjKeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(Label_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G52RKPtjKkT",
        "outputId": "a2d371dd-f68a-488c-8889-a82e84aa324e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9758333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "Y1_VDVVYjCV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model_LTE_WiFi_coexistance_histogram+IPI.h5')"
      ],
      "metadata": {
        "id": "_SWX0Y5rjdUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512"
      ],
      "metadata": {
        "id": "7Bo4qJ9ljdf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"dataset_test.csv\", header=None)"
      ],
      "metadata": {
        "id": "sx0wUrwYjku9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BSCoA6v5jkyZ",
        "outputId": "52bafa66-f836-4112-9b71-6668259d1e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0       1       2       3       4       5       6       7       8   \\\n",
              "0   0.0662  0.1324  0.1986  0.2648  0.3310  0.3972  0.4634  0.5296  0.5958   \n",
              "1   0.0662  0.1324  0.1986  0.2648  0.3310  0.3972  0.4634  0.5296  0.5958   \n",
              "2   0.2692  0.5384  0.8076  1.0768  1.3460  1.6152  1.8844  2.1536  2.4228   \n",
              "3   0.0380  0.0760  0.1140  0.1520  0.1900  0.2280  0.2660  0.3040  0.3420   \n",
              "4   0.0383  0.0766  0.1149  0.1532  0.1915  0.2298  0.2681  0.3064  0.3447   \n",
              "5   0.0373  0.0746  0.1119  0.1492  0.1865  0.2238  0.2611  0.2984  0.3357   \n",
              "6   0.0380  0.0760  0.1140  0.1520  0.1900  0.2280  0.2660  0.3040  0.3420   \n",
              "7   0.0376  0.0752  0.1128  0.1504  0.1880  0.2256  0.2632  0.3008  0.3384   \n",
              "8   0.0379  0.0758  0.1137  0.1516  0.1895  0.2274  0.2653  0.3032  0.3411   \n",
              "9   0.0376  0.0752  0.1128  0.1504  0.1880  0.2256  0.2632  0.3008  0.3384   \n",
              "10  0.0584  0.1168  0.1752  0.2336  0.2920  0.3504  0.4088  0.4672  0.5256   \n",
              "11  0.0584  0.1168  0.1752  0.2336  0.2920  0.3504  0.4088  0.4672  0.5256   \n",
              "12  0.0247  0.0494  0.0741  0.0988  0.1235  0.1482  0.1729  0.1976  0.2223   \n",
              "13  0.0146  0.0292  0.0438  0.0584  0.0730  0.0876  0.1022  0.1168  0.1314   \n",
              "14  0.0172  0.0344  0.0516  0.0688  0.0860  0.1032  0.1204  0.1376  0.1548   \n",
              "15  0.0363  0.0726  0.1089  0.1452  0.1815  0.2178  0.2541  0.2904  0.3267   \n",
              "16  0.0363  0.0726  0.1089  0.1452  0.1815  0.2178  0.2541  0.2904  0.3267   \n",
              "17  0.0363  0.0726  0.1089  0.1452  0.1815  0.2178  0.2541  0.2904  0.3267   \n",
              "18  0.0363  0.0726  0.1089  0.1452  0.1815  0.2178  0.2541  0.2904  0.3267   \n",
              "19  0.0088  0.0176  0.0264  0.0352  0.0440  0.0528  0.0616  0.0704  0.0792   \n",
              "20  0.0067  0.0134  0.0201  0.0268  0.0335  0.0402  0.0469  0.0536  0.0603   \n",
              "21  0.0071  0.0142  0.0213  0.0284  0.0355  0.0426  0.0497  0.0568  0.0639   \n",
              "22  0.0074  0.0148  0.0222  0.0296  0.0370  0.0444  0.0518  0.0592  0.0666   \n",
              "23  0.0067  0.0134  0.0201  0.0268  0.0335  0.0402  0.0469  0.0536  0.0603   \n",
              "24  0.0067  0.0134  0.0201  0.0268  0.0335  0.0402  0.0469  0.0536  0.0603   \n",
              "25  0.0071  0.0142  0.0213  0.0284  0.0355  0.0426  0.0497  0.0568  0.0639   \n",
              "26  0.0078  0.0156  0.0234  0.0312  0.0390  0.0468  0.0546  0.0624  0.0702   \n",
              "27  0.0067  0.0134  0.0201  0.0268  0.0335  0.0402  0.0469  0.0536  0.0603   \n",
              "28  0.0085  0.0170  0.0255  0.0340  0.0425  0.0510  0.0595  0.0680  0.0765   \n",
              "29  0.0085  0.0170  0.0255  0.0340  0.0425  0.0510  0.0595  0.0680  0.0765   \n",
              "30  0.0074  0.0148  0.0222  0.0296  0.0370  0.0444  0.0518  0.0592  0.0666   \n",
              "31  0.0080  0.0160  0.0240  0.0320  0.0400  0.0480  0.0560  0.0640  0.0720   \n",
              "32  0.0073  0.0146  0.0219  0.0292  0.0365  0.0438  0.0511  0.0584  0.0657   \n",
              "33  0.0081  0.0162  0.0243  0.0324  0.0405  0.0486  0.0567  0.0648  0.0729   \n",
              "34  0.0109  0.0218  0.0327  0.0436  0.0545  0.0654  0.0763  0.0872  0.0981   \n",
              "35  0.0122  0.0244  0.0366  0.0488  0.0610  0.0732  0.0854  0.0976  0.1098   \n",
              "36  0.0101  0.0202  0.0303  0.0404  0.0505  0.0606  0.0707  0.0808  0.0909   \n",
              "37  0.0111  0.0222  0.0333  0.0444  0.0555  0.0666  0.0777  0.0888  0.0999   \n",
              "38  0.0104  0.0208  0.0312  0.0416  0.0520  0.0624  0.0728  0.0832  0.0936   \n",
              "39  0.0118  0.0236  0.0354  0.0472  0.0590  0.0708  0.0826  0.0944  0.1062   \n",
              "40  0.0078  0.0156  0.0234  0.0312  0.0390  0.0468  0.0546  0.0624  0.0702   \n",
              "41  0.0074  0.0148  0.0222  0.0296  0.0370  0.0444  0.0518  0.0592  0.0666   \n",
              "42  0.0060  0.0120  0.0180  0.0240  0.0300  0.0360  0.0420  0.0480  0.0540   \n",
              "43  0.0072  0.0144  0.0216  0.0288  0.0360  0.0432  0.0504  0.0576  0.0648   \n",
              "44  0.0067  0.0134  0.0201  0.0268  0.0335  0.0402  0.0469  0.0536  0.0603   \n",
              "45  0.1557  0.3114  0.4671  0.6228  0.7785  0.9342  1.0899  1.2456  1.4013   \n",
              "46  0.0723  0.1446  0.2169  0.2892  0.3615  0.4338  0.5061  0.5784  0.6507   \n",
              "47  0.0804  0.1608  0.2412  0.3216  0.4020  0.4824  0.5628  0.6432  0.7236   \n",
              "48  0.0390  0.0780  0.1170  0.1560  0.1950  0.2340  0.2730  0.3120  0.3510   \n",
              "49  0.0470  0.0940  0.1410  0.1880  0.2350  0.2820  0.3290  0.3760  0.4230   \n",
              "\n",
              "       9   ...      45      46      47      48      49      50      51  \\\n",
              "0   0.662  ...  0.0008  0.0000  0.0000  0.0000  0.0008  0.0004  0.0776   \n",
              "1   0.662  ...  0.0004  0.0000  0.0004  0.0000  0.0008  0.0008  0.0792   \n",
              "2   2.692  ...  0.0000  0.0021  0.0010  0.0000  0.0052  0.0010  0.2884   \n",
              "3   0.380  ...  0.0000  0.0000  0.0000  0.0120  0.0176  0.0060  0.0056   \n",
              "4   0.383  ...  0.0000  0.0008  0.0000  0.0116  0.0180  0.0084  0.0032   \n",
              "5   0.373  ...  0.0004  0.0000  0.0000  0.0000  0.0168  0.0136  0.0092   \n",
              "6   0.380  ...  0.0000  0.0004  0.0004  0.0096  0.0168  0.0104  0.0048   \n",
              "7   0.376  ...  0.0008  0.0000  0.0000  0.0040  0.0204  0.0112  0.0064   \n",
              "8   0.379  ...  0.0008  0.0000  0.0000  0.0076  0.0168  0.0108  0.0048   \n",
              "9   0.376  ...  0.0004  0.0004  0.0000  0.0040  0.0196  0.0092  0.0076   \n",
              "10  0.584  ...  0.0260  0.0096  0.0108  0.0060  0.0036  0.0024  0.0144   \n",
              "11  0.584  ...  0.0264  0.0076  0.0132  0.0032  0.0036  0.0056  0.0140   \n",
              "12  0.247  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0004  0.0012   \n",
              "13  0.146  ...  0.0244  0.0100  0.0196  0.0108  0.0040  0.0104  0.0024   \n",
              "14  0.172  ...  0.0080  0.0028  0.0080  0.0016  0.0000  0.0000  0.0004   \n",
              "15  0.363  ...  0.0012  0.0004  0.0000  0.0016  0.0000  0.0004  0.0368   \n",
              "16  0.363  ...  0.0000  0.0000  0.0000  0.0000  0.0004  0.0000  0.0424   \n",
              "17  0.363  ...  0.0008  0.0000  0.0000  0.0004  0.0000  0.0004  0.0424   \n",
              "18  0.363  ...  0.0000  0.0008  0.0000  0.0004  0.0004  0.0000  0.0360   \n",
              "19  0.088  ...  0.0004  0.0000  0.0004  0.0000  0.0000  0.0000  0.0004   \n",
              "20  0.067  ...  0.0084  0.0064  0.0008  0.0032  0.0016  0.0004  0.0004   \n",
              "21  0.071  ...  0.0044  0.0048  0.0000  0.0008  0.0004  0.0012  0.0004   \n",
              "22  0.074  ...  0.0024  0.0000  0.0008  0.0004  0.0004  0.0004  0.0004   \n",
              "23  0.067  ...  0.0136  0.0048  0.0004  0.0028  0.0016  0.0008  0.0008   \n",
              "24  0.067  ...  0.0116  0.0064  0.0004  0.0024  0.0012  0.0000  0.0008   \n",
              "25  0.071  ...  0.0060  0.0032  0.0004  0.0000  0.0004  0.0000  0.0004   \n",
              "26  0.078  ...  0.0012  0.0020  0.0020  0.0012  0.0012  0.0000  0.0004   \n",
              "27  0.067  ...  0.0088  0.0076  0.0016  0.0016  0.0024  0.0016  0.0012   \n",
              "28  0.085  ...  0.0012  0.0004  0.0004  0.0004  0.0004  0.0000  0.0004   \n",
              "29  0.085  ...  0.0020  0.0000  0.0000  0.0000  0.0004  0.0004  0.0004   \n",
              "30  0.074  ...  0.0076  0.0004  0.0012  0.0012  0.0004  0.0004  0.0004   \n",
              "31  0.080  ...  0.0032  0.0012  0.0012  0.0004  0.0000  0.0000  0.0012   \n",
              "32  0.073  ...  0.0068  0.0040  0.0016  0.0024  0.0008  0.0000  0.0008   \n",
              "33  0.081  ...  0.0036  0.0028  0.0016  0.0000  0.0000  0.0004  0.0008   \n",
              "34  0.109  ...  0.0016  0.0012  0.0004  0.0000  0.0000  0.0000  0.0004   \n",
              "35  0.122  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0004  0.0004   \n",
              "36  0.101  ...  0.0028  0.0000  0.0008  0.0000  0.0000  0.0000  0.0004   \n",
              "37  0.111  ...  0.0020  0.0004  0.0008  0.0004  0.0000  0.0000  0.0008   \n",
              "38  0.104  ...  0.0008  0.0000  0.0000  0.0004  0.0004  0.0000  0.0004   \n",
              "39  0.118  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0004   \n",
              "40  0.078  ...  0.0000  0.0008  0.0000  0.0000  0.0008  0.0004  0.0004   \n",
              "41  0.074  ...  0.0016  0.0000  0.0008  0.0012  0.0000  0.0000  0.0004   \n",
              "42  0.060  ...  0.0044  0.0272  0.0104  0.0000  0.0020  0.0016  0.0004   \n",
              "43  0.072  ...  0.0044  0.0004  0.0004  0.0000  0.0004  0.0000  0.0004   \n",
              "44  0.067  ...  0.0100  0.0032  0.0000  0.0024  0.0004  0.0004  0.0004   \n",
              "45  1.557  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0004   \n",
              "46  0.723  ...  0.0000  0.0000  0.0004  0.0004  0.0000  0.0284  0.0320   \n",
              "47  0.804  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0004  0.0020   \n",
              "48  0.390  ...  0.0000  0.0000  0.0000  0.0004  0.0000  0.0000  0.0304   \n",
              "49  0.470  ...  0.0000  0.0000  0.0000  0.0028  0.0284  0.0088  0.0044   \n",
              "\n",
              "        52      53  54  \n",
              "0   0.2282  0.9463   0  \n",
              "1   0.2293  0.9524   0  \n",
              "2   1.5919  0.9828   0  \n",
              "3   0.1430  0.9826   0  \n",
              "4   0.1428  0.9810   0  \n",
              "5   0.1428  0.9810   0  \n",
              "6   0.1438  0.9873   0  \n",
              "7   0.1432  0.9841   0  \n",
              "8   0.1421  0.9778   0  \n",
              "9   0.1430  0.9826   0  \n",
              "10  0.1738  0.9928   0  \n",
              "11  0.1733  0.9944   0  \n",
              "12  0.0795  0.9662   0  \n",
              "13  0.0785  0.9662   0  \n",
              "14  0.0786  0.9662   0  \n",
              "15  0.1093  0.9670   0  \n",
              "16  0.1085  0.9778   0  \n",
              "17  0.1082  0.9794   0  \n",
              "18  0.1065  0.9685   0  \n",
              "19  0.0454  0.7301   1  \n",
              "20  0.0466  0.7100   1  \n",
              "21  0.0471  0.6938   1  \n",
              "22  0.0465  0.7030   1  \n",
              "23  0.0474  0.6984   1  \n",
              "24  0.0467  0.7100   1  \n",
              "25  0.0468  0.7100   1  \n",
              "26  0.0454  0.7801   1  \n",
              "27  0.0456  0.7687   1  \n",
              "28  0.0444  0.7788   1  \n",
              "29  0.0451  0.7813   1  \n",
              "30  0.0453  0.7813   1  \n",
              "31  0.0459  0.7738   1  \n",
              "32  0.0453  0.7750   1  \n",
              "33  0.0464  0.7687   1  \n",
              "34  0.0467  0.8622   1  \n",
              "35  0.0458  0.8636   1  \n",
              "36  0.0462  0.8609   1  \n",
              "37  0.0460  0.8790   1  \n",
              "38  0.0444  0.8790   1  \n",
              "39  0.0486  0.6667   1  \n",
              "40  0.0497  0.6351   1  \n",
              "41  0.0484  0.6513   1  \n",
              "42  0.0495  0.6372   1  \n",
              "43  0.0491  0.6437   1  \n",
              "44  0.0485  0.6469   1  \n",
              "45  0.2532  0.8918   0  \n",
              "46  0.2474  0.8828   0  \n",
              "47  0.1507  0.9673   0  \n",
              "48  0.1440  0.9789   0  \n",
              "49  0.1806  0.9697   0  \n",
              "\n",
              "[50 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fa98a10-3db5-4755-a4d2-e99f24b89161\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0662</td>\n",
              "      <td>0.1324</td>\n",
              "      <td>0.1986</td>\n",
              "      <td>0.2648</td>\n",
              "      <td>0.3310</td>\n",
              "      <td>0.3972</td>\n",
              "      <td>0.4634</td>\n",
              "      <td>0.5296</td>\n",
              "      <td>0.5958</td>\n",
              "      <td>0.662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0776</td>\n",
              "      <td>0.2282</td>\n",
              "      <td>0.9463</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0662</td>\n",
              "      <td>0.1324</td>\n",
              "      <td>0.1986</td>\n",
              "      <td>0.2648</td>\n",
              "      <td>0.3310</td>\n",
              "      <td>0.3972</td>\n",
              "      <td>0.4634</td>\n",
              "      <td>0.5296</td>\n",
              "      <td>0.5958</td>\n",
              "      <td>0.662</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0792</td>\n",
              "      <td>0.2293</td>\n",
              "      <td>0.9524</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.2692</td>\n",
              "      <td>0.5384</td>\n",
              "      <td>0.8076</td>\n",
              "      <td>1.0768</td>\n",
              "      <td>1.3460</td>\n",
              "      <td>1.6152</td>\n",
              "      <td>1.8844</td>\n",
              "      <td>2.1536</td>\n",
              "      <td>2.4228</td>\n",
              "      <td>2.692</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.2884</td>\n",
              "      <td>1.5919</td>\n",
              "      <td>0.9828</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0380</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2660</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.3420</td>\n",
              "      <td>0.380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.1430</td>\n",
              "      <td>0.9826</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0766</td>\n",
              "      <td>0.1149</td>\n",
              "      <td>0.1532</td>\n",
              "      <td>0.1915</td>\n",
              "      <td>0.2298</td>\n",
              "      <td>0.2681</td>\n",
              "      <td>0.3064</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.1428</td>\n",
              "      <td>0.9810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.0746</td>\n",
              "      <td>0.1119</td>\n",
              "      <td>0.1492</td>\n",
              "      <td>0.1865</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.2611</td>\n",
              "      <td>0.2984</td>\n",
              "      <td>0.3357</td>\n",
              "      <td>0.373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0092</td>\n",
              "      <td>0.1428</td>\n",
              "      <td>0.9810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0380</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.1900</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2660</td>\n",
              "      <td>0.3040</td>\n",
              "      <td>0.3420</td>\n",
              "      <td>0.380</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1438</td>\n",
              "      <td>0.9873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0376</td>\n",
              "      <td>0.0752</td>\n",
              "      <td>0.1128</td>\n",
              "      <td>0.1504</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>0.2632</td>\n",
              "      <td>0.3008</td>\n",
              "      <td>0.3384</td>\n",
              "      <td>0.376</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>0.1432</td>\n",
              "      <td>0.9841</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0379</td>\n",
              "      <td>0.0758</td>\n",
              "      <td>0.1137</td>\n",
              "      <td>0.1516</td>\n",
              "      <td>0.1895</td>\n",
              "      <td>0.2274</td>\n",
              "      <td>0.2653</td>\n",
              "      <td>0.3032</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.379</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0108</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.1421</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0376</td>\n",
              "      <td>0.0752</td>\n",
              "      <td>0.1128</td>\n",
              "      <td>0.1504</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.2256</td>\n",
              "      <td>0.2632</td>\n",
              "      <td>0.3008</td>\n",
              "      <td>0.3384</td>\n",
              "      <td>0.376</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0196</td>\n",
              "      <td>0.0092</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.1430</td>\n",
              "      <td>0.9826</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0584</td>\n",
              "      <td>0.1168</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3504</td>\n",
              "      <td>0.4088</td>\n",
              "      <td>0.4672</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>0.0108</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0144</td>\n",
              "      <td>0.1738</td>\n",
              "      <td>0.9928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0584</td>\n",
              "      <td>0.1168</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.2336</td>\n",
              "      <td>0.2920</td>\n",
              "      <td>0.3504</td>\n",
              "      <td>0.4088</td>\n",
              "      <td>0.4672</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.1733</td>\n",
              "      <td>0.9944</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>0.0741</td>\n",
              "      <td>0.0988</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.1482</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.1976</td>\n",
              "      <td>0.2223</td>\n",
              "      <td>0.247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0438</td>\n",
              "      <td>0.0584</td>\n",
              "      <td>0.0730</td>\n",
              "      <td>0.0876</td>\n",
              "      <td>0.1022</td>\n",
              "      <td>0.1168</td>\n",
              "      <td>0.1314</td>\n",
              "      <td>0.146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0196</td>\n",
              "      <td>0.0108</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0785</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0172</td>\n",
              "      <td>0.0344</td>\n",
              "      <td>0.0516</td>\n",
              "      <td>0.0688</td>\n",
              "      <td>0.0860</td>\n",
              "      <td>0.1032</td>\n",
              "      <td>0.1204</td>\n",
              "      <td>0.1376</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.172</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0786</td>\n",
              "      <td>0.9662</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.1452</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2904</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.363</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1093</td>\n",
              "      <td>0.9670</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.1452</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2904</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.363</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0424</td>\n",
              "      <td>0.1085</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.1452</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2904</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.363</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0424</td>\n",
              "      <td>0.1082</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0726</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.1452</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.2178</td>\n",
              "      <td>0.2541</td>\n",
              "      <td>0.2904</td>\n",
              "      <td>0.3267</td>\n",
              "      <td>0.363</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.1065</td>\n",
              "      <td>0.9685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0352</td>\n",
              "      <td>0.0440</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0616</td>\n",
              "      <td>0.0704</td>\n",
              "      <td>0.0792</td>\n",
              "      <td>0.088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0454</td>\n",
              "      <td>0.7301</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.0402</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>0.0536</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0466</td>\n",
              "      <td>0.7100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0071</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0355</td>\n",
              "      <td>0.0426</td>\n",
              "      <td>0.0497</td>\n",
              "      <td>0.0568</td>\n",
              "      <td>0.0639</td>\n",
              "      <td>0.071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0471</td>\n",
              "      <td>0.6938</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0074</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0296</td>\n",
              "      <td>0.0370</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0518</td>\n",
              "      <td>0.0592</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0465</td>\n",
              "      <td>0.7030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.0402</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>0.0536</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0474</td>\n",
              "      <td>0.6984</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.0402</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>0.0536</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0467</td>\n",
              "      <td>0.7100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0071</td>\n",
              "      <td>0.0142</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0355</td>\n",
              "      <td>0.0426</td>\n",
              "      <td>0.0497</td>\n",
              "      <td>0.0568</td>\n",
              "      <td>0.0639</td>\n",
              "      <td>0.071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0468</td>\n",
              "      <td>0.7100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0234</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0390</td>\n",
              "      <td>0.0468</td>\n",
              "      <td>0.0546</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.0702</td>\n",
              "      <td>0.078</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0454</td>\n",
              "      <td>0.7801</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.0402</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>0.0536</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0456</td>\n",
              "      <td>0.7687</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0170</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.0425</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.0680</td>\n",
              "      <td>0.0765</td>\n",
              "      <td>0.085</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0170</td>\n",
              "      <td>0.0255</td>\n",
              "      <td>0.0340</td>\n",
              "      <td>0.0425</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.0680</td>\n",
              "      <td>0.0765</td>\n",
              "      <td>0.085</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0451</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0074</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0296</td>\n",
              "      <td>0.0370</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0518</td>\n",
              "      <td>0.0592</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0320</td>\n",
              "      <td>0.0400</td>\n",
              "      <td>0.0480</td>\n",
              "      <td>0.0560</td>\n",
              "      <td>0.0640</td>\n",
              "      <td>0.0720</td>\n",
              "      <td>0.080</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0459</td>\n",
              "      <td>0.7738</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0219</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0365</td>\n",
              "      <td>0.0438</td>\n",
              "      <td>0.0511</td>\n",
              "      <td>0.0584</td>\n",
              "      <td>0.0657</td>\n",
              "      <td>0.073</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.7750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0162</td>\n",
              "      <td>0.0243</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0405</td>\n",
              "      <td>0.0486</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>0.0648</td>\n",
              "      <td>0.0729</td>\n",
              "      <td>0.081</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0464</td>\n",
              "      <td>0.7687</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.0218</td>\n",
              "      <td>0.0327</td>\n",
              "      <td>0.0436</td>\n",
              "      <td>0.0545</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>0.0763</td>\n",
              "      <td>0.0872</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.109</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0467</td>\n",
              "      <td>0.8622</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0122</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0366</td>\n",
              "      <td>0.0488</td>\n",
              "      <td>0.0610</td>\n",
              "      <td>0.0732</td>\n",
              "      <td>0.0854</td>\n",
              "      <td>0.0976</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0458</td>\n",
              "      <td>0.8636</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0404</td>\n",
              "      <td>0.0505</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.0707</td>\n",
              "      <td>0.0808</td>\n",
              "      <td>0.0909</td>\n",
              "      <td>0.101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0462</td>\n",
              "      <td>0.8609</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0111</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0555</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0777</td>\n",
              "      <td>0.0888</td>\n",
              "      <td>0.0999</td>\n",
              "      <td>0.111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0460</td>\n",
              "      <td>0.8790</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>0.0520</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.0728</td>\n",
              "      <td>0.0832</td>\n",
              "      <td>0.0936</td>\n",
              "      <td>0.104</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.8790</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0118</td>\n",
              "      <td>0.0236</td>\n",
              "      <td>0.0354</td>\n",
              "      <td>0.0472</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0708</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0944</td>\n",
              "      <td>0.1062</td>\n",
              "      <td>0.118</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0486</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0078</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0234</td>\n",
              "      <td>0.0312</td>\n",
              "      <td>0.0390</td>\n",
              "      <td>0.0468</td>\n",
              "      <td>0.0546</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.0702</td>\n",
              "      <td>0.078</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0497</td>\n",
              "      <td>0.6351</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0074</td>\n",
              "      <td>0.0148</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>0.0296</td>\n",
              "      <td>0.0370</td>\n",
              "      <td>0.0444</td>\n",
              "      <td>0.0518</td>\n",
              "      <td>0.0592</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0008</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0484</td>\n",
              "      <td>0.6513</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.0060</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>0.0480</td>\n",
              "      <td>0.0540</td>\n",
              "      <td>0.060</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0495</td>\n",
              "      <td>0.6372</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0144</td>\n",
              "      <td>0.0216</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>0.0432</td>\n",
              "      <td>0.0504</td>\n",
              "      <td>0.0576</td>\n",
              "      <td>0.0648</td>\n",
              "      <td>0.072</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0491</td>\n",
              "      <td>0.6437</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0134</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0335</td>\n",
              "      <td>0.0402</td>\n",
              "      <td>0.0469</td>\n",
              "      <td>0.0536</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0024</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.6469</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.1557</td>\n",
              "      <td>0.3114</td>\n",
              "      <td>0.4671</td>\n",
              "      <td>0.6228</td>\n",
              "      <td>0.7785</td>\n",
              "      <td>0.9342</td>\n",
              "      <td>1.0899</td>\n",
              "      <td>1.2456</td>\n",
              "      <td>1.4013</td>\n",
              "      <td>1.557</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.2532</td>\n",
              "      <td>0.8918</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.0723</td>\n",
              "      <td>0.1446</td>\n",
              "      <td>0.2169</td>\n",
              "      <td>0.2892</td>\n",
              "      <td>0.3615</td>\n",
              "      <td>0.4338</td>\n",
              "      <td>0.5061</td>\n",
              "      <td>0.5784</td>\n",
              "      <td>0.6507</td>\n",
              "      <td>0.723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0320</td>\n",
              "      <td>0.2474</td>\n",
              "      <td>0.8828</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.0804</td>\n",
              "      <td>0.1608</td>\n",
              "      <td>0.2412</td>\n",
              "      <td>0.3216</td>\n",
              "      <td>0.4020</td>\n",
              "      <td>0.4824</td>\n",
              "      <td>0.5628</td>\n",
              "      <td>0.6432</td>\n",
              "      <td>0.7236</td>\n",
              "      <td>0.804</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.1507</td>\n",
              "      <td>0.9673</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.0390</td>\n",
              "      <td>0.0780</td>\n",
              "      <td>0.1170</td>\n",
              "      <td>0.1560</td>\n",
              "      <td>0.1950</td>\n",
              "      <td>0.2340</td>\n",
              "      <td>0.2730</td>\n",
              "      <td>0.3120</td>\n",
              "      <td>0.3510</td>\n",
              "      <td>0.390</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0004</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0304</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.9789</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.0470</td>\n",
              "      <td>0.0940</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.1880</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.2820</td>\n",
              "      <td>0.3290</td>\n",
              "      <td>0.3760</td>\n",
              "      <td>0.4230</td>\n",
              "      <td>0.470</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0284</td>\n",
              "      <td>0.0088</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.1806</td>\n",
              "      <td>0.9697</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50 rows × 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fa98a10-3db5-4755-a4d2-e99f24b89161')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fa98a10-3db5-4755-a4d2-e99f24b89161 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fa98a10-3db5-4755-a4d2-e99f24b89161');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual = df.iloc[:,54].to_numpy()"
      ],
      "metadata": {
        "id": "Dyd8ZSLDkAav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz2A_TIckAn_",
        "outputId": "c1b0ce3a-f199-42ea-cf65-efc9a1353fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df.iloc[:,0:26].to_numpy()\n",
        "Y_test = df.iloc[:,26:52].to_numpy()\n",
        "IPI = df.iloc[:,52].to_numpy()"
      ],
      "metadata": {
        "id": "zjMDSsv-kF4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "T=0\n",
        "for i in range (100):\n",
        "    start=time.perf_counter()\n",
        "    y_pred=model.predict([X_test, Y_test, np.transpose(IPI)])\n",
        "    tt=time.perf_counter() - start\n",
        "    T=T+tt\n",
        "print (\"%s\"  % (T/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAbXtUCzkGCH",
        "outputId": "34b8d0f6-662a-4514-d9a2-1e4c3afb803d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 10ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 14ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 19ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 18ms/step\n",
            "2/2 [==============================] - 0s 13ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 9ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 11ms/step\n",
            "2/2 [==============================] - 0s 8ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.1287924497299855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(y_pred, axis=-1)"
      ],
      "metadata": {
        "id": "nAlo78tVkqF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_actual, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EPyCMgtkrYG",
        "outputId": "e18b5b53-c512-48a3-ef9c-a688dd6e598f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n"
          ]
        }
      ]
    }
  ]
}